{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83daa6cf",
   "metadata": {},
   "source": [
    "# Forest Fires Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb065f4c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9101556",
   "metadata": {
    "id": "f9101556"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e7a3b",
   "metadata": {},
   "source": [
    "## Imports from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vx2R-IEVjdxa",
   "metadata": {
    "id": "Vx2R-IEVjdxa"
   },
   "outputs": [],
   "source": [
    "# Refer README.txt for installation steps\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188cc488",
   "metadata": {},
   "source": [
    "## Reading train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56586f7d",
   "metadata": {
    "id": "56586f7d"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"algerian_fires_train.csv\")\n",
    "test=pd.read_csv(\"algerian_fires_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90197de",
   "metadata": {},
   "source": [
    "## Looking at the distribution of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c9d34",
   "metadata": {
    "id": "4a0c9d34"
   },
   "outputs": [],
   "source": [
    "def class_distribution(df):\n",
    "    '''\n",
    "    Function to generate data distribution as a pie chart\n",
    "    \n",
    "    Parameters:\n",
    "    df: input data frame\n",
    "    \n",
    "    Return:\n",
    "    Pie chart showing the distribution of the classes\n",
    "    '''\n",
    "    class_list=[len(df[df.iloc[:,-1]==1]),len(df[df.iloc[:,-1]==0])]\n",
    "    col = sns.color_palette('Set2')\n",
    "    labels = ['Class Fire', 'Class No Fire']\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.pie(class_list, labels=labels,colors =col , autopct = '%0.0f%%')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8e486",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "80b8e486",
    "outputId": "861fae77-d15b-4606-e0b3-10c79c3877c6"
   },
   "outputs": [],
   "source": [
    "class_distribution(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab05728",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b260cc",
   "metadata": {
    "id": "76b260cc"
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    '''\n",
    "    Function to create features from the date column of the data frame\n",
    "    \n",
    "    Parameters:\n",
    "    df: input data frame for which extra features need to be created\n",
    "\n",
    "    Return:\n",
    "    df: updated data frame\n",
    "    '''\n",
    "\n",
    "    df['Date']=pd.to_datetime(df['Date'],format=\"%d/%m/%Y\")# convert to pandas datetime format\n",
    "    df['Month']=df['Date'].dt.month# extract month\n",
    "    df['Day']=df['Date'].dt.day_name()# extract date\n",
    "    df=pd.get_dummies(df,columns=['Day'],prefix=\"\",prefix_sep=\"\")# one hot encoding for the days\n",
    "    class_col=df.pop('Classes')\n",
    "    df.insert(len(df.columns), \"Classes\", class_col )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m_OaEa66XzWq",
   "metadata": {
    "id": "m_OaEa66XzWq"
   },
   "outputs": [],
   "source": [
    "train=create_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tq7DFssLYQHT",
   "metadata": {
    "id": "tq7DFssLYQHT"
   },
   "outputs": [],
   "source": [
    "test=create_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892bbce9",
   "metadata": {
    "id": "892bbce9"
   },
   "outputs": [],
   "source": [
    "def moving_avg(df):\n",
    "    '''\n",
    "    Function to create a column with moving average of temperature from the temperature column of the data frame\n",
    "    \n",
    "    Parameters:\n",
    "    df: input data frame\n",
    "\n",
    "    Return:\n",
    "    df: updated data frame\n",
    "    '''\n",
    "    df2=df.copy(deep=True)\n",
    "    df2['Rolling_Temp'] = df2['Temperature'].rolling(10).mean()\n",
    "    df2.Rolling_Temp.fillna(df2['Temperature'].iloc[0:10],inplace=True)\n",
    "    \n",
    "    for i in range(8, len(df)-1, 2):\n",
    "        df2.loc[i, 'Rolling_Temp'] = df2.loc[i+1, 'Rolling_Temp']\n",
    "    roll_temp=df2.pop('Rolling_Temp')\n",
    "    df2.insert(2, \"Rolling_Temp\", roll_temp )\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_Ve1Q5nnYQKd",
   "metadata": {
    "id": "_Ve1Q5nnYQKd"
   },
   "outputs": [],
   "source": [
    "train_mov=moving_avg(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lrUAzhEzYQMz",
   "metadata": {
    "id": "lrUAzhEzYQMz"
   },
   "outputs": [],
   "source": [
    "test_mov=moving_avg(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AhGIoaxkauMa",
   "metadata": {
    "id": "AhGIoaxkauMa"
   },
   "source": [
    "## Feature Engineering and Dimensionality Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176224dc",
   "metadata": {},
   "source": [
    "### Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402d3ab",
   "metadata": {
    "id": "0402d3ab"
   },
   "outputs": [],
   "source": [
    "def pearson(df):\n",
    "    '''\n",
    "    Function to create a heatmap showing the correlation between all the features by using the Pearson correlation \n",
    "    \n",
    "    Parameters:\n",
    "    df: input dataframe\n",
    "\n",
    "    Return:\n",
    "    Heatmap showing the correlation between all the features\n",
    "    '''\n",
    "    plt.figure(figsize=(14,14))\n",
    "    cor = df.corr(method='pearson')\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(cor, annot=True, cmap=\"YlGnBu\",ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K-fD-SqNaChR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "K-fD-SqNaChR",
    "outputId": "647ad95c-6fd6-45fe-b39e-00496fc113b0"
   },
   "outputs": [],
   "source": [
    "pearson(train_mov.iloc[:,1:-1])# generate the heatmap for all the features except the dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5dc42",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551b021",
   "metadata": {
    "id": "8551b021"
   },
   "outputs": [],
   "source": [
    "def pca_analysis(df):\n",
    "    '''\n",
    "    Function to perform feature analysis using PCA\n",
    "    \n",
    "    Parameters:\n",
    "    df:input data frame\n",
    "\n",
    "    Return:\n",
    "    Plot of feature analysis using PCA\n",
    "    '''\n",
    "    pca = PCA()\n",
    "    pca.fit(df)\n",
    "    n_components = np.arange(pca.n_components_) + 1\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(n_components, pca.explained_variance_ratio_.cumsum(), 'o-', linewidth=2, color='green')\n",
    "    plt.xlabel('Features (principal components)')\n",
    "    plt.ylabel('Total Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8CDXQDK4a5xs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "8CDXQDK4a5xs",
    "outputId": "eb583540-52bb-4e3b-fb89-ae211a1c1857"
   },
   "outputs": [],
   "source": [
    "pca_analysis(train_mov.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddf8a7",
   "metadata": {
    "id": "6eddf8a7"
   },
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    '''\n",
    "    Function to drop the columns after the analysis from dimensionality reduction\n",
    "    \n",
    "    Parameters:\n",
    "    df: input data frame\n",
    "\n",
    "    Return:\n",
    "    data frame after dropping columns\n",
    "    '''\n",
    "    df.drop(['Date','RH','Rain','Ws','Friday','Monday','Saturday','Sunday','Thursday','Tuesday','Wednesday'],axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y0UG1wJNbJVx",
   "metadata": {
    "id": "y0UG1wJNbJVx"
   },
   "outputs": [],
   "source": [
    "train_mov=drop_columns(train_mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oqkZRB5WbJiI",
   "metadata": {
    "id": "oqkZRB5WbJiI"
   },
   "outputs": [],
   "source": [
    "test_mov=drop_columns(test_mov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebac0b",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hQP2sJiaOoJ3",
   "metadata": {
    "id": "hQP2sJiaOoJ3"
   },
   "outputs": [],
   "source": [
    "def standardize(train_data,test_data):\n",
    "    scaler = StandardScaler()\n",
    "    train_data= scaler.fit_transform(train_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6sHnBWnCPy-v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6sHnBWnCPy-v",
    "outputId": "d2c1d39c-7aad-4abc-e13f-e1e653eb4b87"
   },
   "outputs": [],
   "source": [
    "train_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NKmEDk7bOoUV",
   "metadata": {
    "id": "NKmEDk7bOoUV"
   },
   "outputs": [],
   "source": [
    "train_mov.iloc[:,0:-2],test_mov.iloc[:,0:-2]=standardize(train_mov.iloc[:,0:-2],test_mov.iloc[:,0:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0aaae5",
   "metadata": {},
   "source": [
    "#### Eliminating the last 8 points from the train data to avoid past data influencing future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27ac39",
   "metadata": {
    "id": "ca27ac39"
   },
   "outputs": [],
   "source": [
    "train_mov = train_mov.loc[0:train_mov.shape[0]-9,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006eaaa",
   "metadata": {},
   "source": [
    "## Plot for distribution of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43a664",
   "metadata": {
    "id": "fe43a664"
   },
   "outputs": [],
   "source": [
    "def plot_feature_distribution(df):\n",
    "    '''\n",
    "    Function to create subplots of the distribution of the features\n",
    "    \n",
    "    Parameters:\n",
    "    df: input data frame\n",
    "\n",
    "    Return:\n",
    "    plots of the distribution of each feature\n",
    "    '''\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(22, 12))\n",
    "\n",
    "    sns.histplot(df['Temperature'],ax=axes[0, 0],color='purple', kde=True, stat=\"density\", linewidth=0)\n",
    "    sns.histplot(df['Rolling_Temp'],ax=axes[0, 1],color='purple', kde=True, stat=\"density\", linewidth=0)\n",
    "    sns.histplot(df['FFMC'],ax=axes[0, 2],color='purple', kde=True, stat=\"density\", linewidth=0)\n",
    "    sns.histplot(df['DMC'],ax=axes[0, 3],color='purple', kde=True, stat=\"density\", linewidth=0)\n",
    "\n",
    "    sns.histplot(df['DC'],ax=axes[1, 0],color='purple', kde=True, stat=\"density\", linewidth=0)\n",
    "    sns.histplot(df['ISI'],ax=axes[1, 1],color='purple', kde=True, stat=\"density\", linewidth=0).set_xlim(-2,3.5)\n",
    "    sns.histplot(df['BUI'],ax=axes[1, 2],color='purple', kde=True, stat=\"density\", linewidth=0)\n",
    "    sns.histplot(df['Month'],ax=axes[1, 3],color='purple', linewidth=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959f755",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "e959f755",
    "outputId": "ce370d26-8138-4093-e97d-059dbabc0476"
   },
   "outputs": [],
   "source": [
    "plot_feature_distribution(train_mov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EVtf3D7ncOxY",
   "metadata": {
    "id": "EVtf3D7ncOxY"
   },
   "source": [
    "\n",
    "#### Convert train and test to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29768a33",
   "metadata": {
    "id": "29768a33"
   },
   "outputs": [],
   "source": [
    "train_mov_np=train_mov.to_numpy()\n",
    "test_mov_np=test_mov.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2cf19c",
   "metadata": {
    "id": "8f2cf19c"
   },
   "outputs": [],
   "source": [
    "def performance_measure(output, target):\n",
    "    '''Function to compute the accuracy and F1 score for a given dataset\n",
    "    \n",
    "    Parameters:\n",
    "    output: Output class labels after model fitting\n",
    "    target: Actual class labels in the dataset\n",
    "    \n",
    "    Return \n",
    "    Computed accuracy and F1 scores\n",
    "    '''\n",
    "    \n",
    "    accuracy = accuracy_score(target, output)\n",
    "    f1_value = f1_score(target, output)\n",
    "    return accuracy, f1_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qLXXsXQY2U3S",
   "metadata": {
    "id": "qLXXsXQY2U3S"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(target, output):\n",
    "    '''\n",
    "    Function to create a confusion matrix\n",
    "    \n",
    "    Parameters:\n",
    "    df: input data frame\n",
    "\n",
    "    Return:\n",
    "    plots of the distribution of each feature\n",
    "    '''\n",
    "    matrix=confusion_matrix(target, output)\n",
    "    ax=sns.heatmap(matrix, annot=True, cmap=\"PiYG\")\n",
    "    ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cbdef",
   "metadata": {
    "id": "e75cbdef"
   },
   "outputs": [],
   "source": [
    "def round_off_values(x):\n",
    "    return round(x,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_SekX6NRAqYh",
   "metadata": {
    "id": "_SekX6NRAqYh"
   },
   "outputs": [],
   "source": [
    "def print_acc_val(train_acc,train_f1,val_acc,val_f1):\n",
    "    print(\"Cross validation train accuracy is\", round_off_values(sum(train_acc)/len(train_acc)))\n",
    "    print(\"Cross validation train F1 is\", round_off_values(sum(train_f1)/len(train_f1)))\n",
    "    print(\"Cross validation validation accuracy is\", round_off_values(sum(val_acc)/len(val_acc)))\n",
    "    print(\"Cross validation validation F1 is\", round_off_values(sum(val_f1)/len(val_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1df2f1",
   "metadata": {
    "id": "dc1df2f1"
   },
   "source": [
    "## Trivial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V7WlWTRR2U-J",
   "metadata": {
    "id": "V7WlWTRR2U-J"
   },
   "outputs": [],
   "source": [
    "def trivial_model_train(dataset, total_batches):\n",
    "    '''\n",
    "    Function to train the trivial model on the train dataset\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: Dataset to train on\n",
    "    total_batches: Number of batches to determine division of train/val data\n",
    "    \n",
    "    Return:\n",
    "    p1: Probability of generating class label of S1\n",
    "    p2: Probability of generating class label of S2\n",
    "    '''\n",
    "    c = total_batches-1\n",
    "    size = int(len(dataset)/total_batches)\n",
    "    \n",
    "    #Dividing the dataset into train and val with an 80/20 split\n",
    "    val_data = dataset[c*size:(c+1)*size,:] \n",
    "    train_data = np.delete(dataset,slice(c*size,(c+1)*size,1),axis=0)\n",
    "    train_data=train_data[0:len(train_data)-8] #deleting past data that could infuence performance on val data\n",
    "\n",
    "    X_train=train_data[:,0:-1]\n",
    "    y_train=train_data[:,-1]\n",
    "    len_train_data = len(y_train)\n",
    "    \n",
    "    X_val=val_data[:,0:-1]\n",
    "    y_val=val_data[:,-1]\n",
    "    len_val_data = len(y_val)\n",
    "                                                    \n",
    "    N1=(y_train == 0).sum() #total number of points belonging to class S1\n",
    "    N2=(y_train == 1).sum() #total number of points belonging to class S2\n",
    "    N=N1+N2\n",
    "    p1=N1/N #probability of point belonging to class S1\n",
    "    p2=N2/N #probability of point belonging to class S2\n",
    "    \n",
    "    y_pred = np.random.binomial(1, p1, len_train_data) #Generating class labels with appropriate probabilities\n",
    "    train_accuracy, train_f1 = performance_measure(y_pred, y_train)\n",
    "        \n",
    "    print(\"Train accuracy is\", round_off_values(train_accuracy))\n",
    "    print(\"Train F1 score is\", round_off_values(train_f1))\n",
    "    \n",
    "    y_pred = np.random.binomial(1, p1, len_val_data) #Generating class labels with appropriate probabilities for the validation dataset \n",
    "    val_accuracy, val_f1 = performance_measure(y_pred, y_val)\n",
    "    \n",
    "    print(\"Validation accuracy is\", round_off_values(val_accuracy))\n",
    "    print(\"Validation F1 score is\",round_off_values( val_f1))\n",
    "    return p1,p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FhVT74B92VAZ",
   "metadata": {
    "id": "FhVT74B92VAZ"
   },
   "outputs": [],
   "source": [
    "def trivial_model_test(p1, y):\n",
    "    '''\n",
    "    Function to test the trivial model on the test dataset\n",
    "    \n",
    "    Parameters:\n",
    "    p1: Probability of generating class label of S1\n",
    "    y: Target class labels in the test dataset\n",
    "    \n",
    "    Return:\n",
    "    none\n",
    "    '''\n",
    "    \n",
    "    y=y.astype(int)\n",
    "    len_test_data=y.shape[0]\n",
    "    \n",
    "    y_pred=np.random.binomial(1,p1,len_test_data) #Generating class labels with appropriate probabilities for the test dataset\n",
    "\n",
    "    test_accuracy, test_f1 = performance_measure(y_pred, y)\n",
    "    print(\"Test accuracy is\", round_off_values(test_accuracy))\n",
    "    print(\"Test F1 score is\", round_off_values(test_f1))\n",
    "    plot_confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb528d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "6fb528d8",
    "outputId": "231d9b5d-c121-413e-9f83-f9f91cf5b518"
   },
   "outputs": [],
   "source": [
    "#Executing the trivial model\n",
    "p1, p2 = trivial_model_train(train_mov_np, 6)\n",
    "trivial_model_test(p1, test_mov_np[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4d200",
   "metadata": {
    "id": "ddb4d200"
   },
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b44ada",
   "metadata": {
    "id": "70b44ada"
   },
   "outputs": [],
   "source": [
    "def nearest_means_classifier_model_train(dataset, total_batches):\n",
    "    '''Function to train the baseline model on the train dataset\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: Dataset to train on\n",
    "    total_batches: Number of batches to determine division of train/val data\n",
    "    \n",
    "    Return:\n",
    "    baseline_model: Model fitted onto the train data\n",
    "    '''\n",
    "    \n",
    "    c = total_batches-1\n",
    "    size = int(len(dataset)/total_batches)\n",
    "    \n",
    "    #Dividing the dataset into train and val with an 80/20 split\n",
    "    val_data=dataset[c*size:(c+1)*size,:] \n",
    "    train_data = np.delete(dataset,slice(c*size,(c+1)*size,1),axis=0)\n",
    "    train_data=train_data[0:len(train_data)-8]\n",
    "\n",
    "    X_train=train_data[:,0:-1]\n",
    "    y_train=train_data[:,-1]\n",
    "    \n",
    "    X_val=val_data[:,0:-1]\n",
    "    y_val=val_data[:,-1]\n",
    "    \n",
    "    baseline_model = NearestCentroid() \n",
    "    \n",
    "    baseline_model.fit(X_train,y_train) #fitting the Nearest means model on train data\n",
    "    y_pred = baseline_model.predict(X_train) #predicting accuracy on train data\n",
    "    \n",
    "    train_accuracy, train_f1 = performance_measure(y_pred, y_train)\n",
    "    print(\"Train accuracy is\", round_off_values(train_accuracy))\n",
    "    print(\"Train F1 score is\", round_off_values(train_f1))\n",
    "    \n",
    "    y_pred = baseline_model.predict(X_val) #predicting accuracy on val data\n",
    "    \n",
    "    val_accuracy, val_f1 = performance_measure(y_pred, y_val)\n",
    "    print(\"Validation accuracy is\", round_off_values(val_accuracy))\n",
    "    print(\"Validation F1 score is\", round_off_values(val_f1))\n",
    "    \n",
    "    return baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a998f29",
   "metadata": {
    "id": "0a998f29"
   },
   "outputs": [],
   "source": [
    "def nearest_means_classifier_model_test(baseline_model, test_data):\n",
    "    '''Function to test the baseline model on the test dataset\n",
    "    \n",
    "    Parameters:\n",
    "    baseline_model: Model fitted onto the train data\n",
    "    test_data: Dataset to test on\n",
    "    \n",
    "    Return:\n",
    "    F1 Score, Accuracy and Confusion Matrix for Test set\n",
    "    '''\n",
    "    \n",
    "    test = test_data[:,0:-1]\n",
    "    y_test = test_data[:,-1].astype(int)\n",
    "    \n",
    "    y_pred = baseline_model.predict(test) #predicting accuracy on test data\n",
    "    \n",
    "    test_accuracy, test_f1 = performance_measure(y_pred, y_test)\n",
    "    print(\"Test Accuracy is\", round_off_values(test_accuracy))\n",
    "    print(\"Test F1 score is\", round_off_values(test_f1))\n",
    "    print('Confusion Matrix for Test Set')\n",
    "    plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba92bf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "3ba92bf4",
    "outputId": "edabba24-64e8-4cde-e332-c8fa16f5ddef"
   },
   "outputs": [],
   "source": [
    "#Executing the baseline model\n",
    "baseline_train_model = nearest_means_classifier_model_train(train_mov_np, 6)\n",
    "nearest_means_classifier_model_test(baseline_train_model, test_mov_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccda044",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0ef35",
   "metadata": {
    "id": "b5f0ef35"
   },
   "outputs": [],
   "source": [
    "def cross_validation(c, dataset, batch_size, flag, weights):\n",
    "    '''\n",
    "    Function to divide the train dataset into batches to perform cross validation\n",
    "    \n",
    "    Parameters:\n",
    "    c: Count of the batch number\n",
    "    dataset: Entire train dataset\n",
    "    batch_size: Total number of partitions required\n",
    "    flag : Used to indicate whether weights should be used\n",
    "    weights: Optional parameter used for weighted Naive Bayes\n",
    "    \n",
    "    Return:\n",
    "    train_data: Train data partition\n",
    "    val_data: Val data partition\n",
    "    '''\n",
    "    \n",
    "    N=len(dataset)\n",
    "    i=int(batch_size)\n",
    "    val_data=dataset[c*i:(c+1)*i,:] #Selecting the validation data partition\n",
    "                    \n",
    "    if c==0:  \n",
    "        val_data = val_data[c*i:len(val_data)-8]\n",
    "        train_data = np.delete(dataset,slice(c*i,(c+1)*i,1),axis=0) #Eliminating val data to obtain train data\n",
    "        if(flag == True):\n",
    "            weight_data = np.delete(weights,slice(c*i,(c+1)*i,1),axis=0)\n",
    "        \n",
    "    elif c==i-1:\n",
    "        train_data = np.delete(dataset,slice(c*i,(c+1)*i,1),axis=0)\n",
    "        train_data=train_data[0:len(train_data)-8]     \n",
    "        if(flag == True):\n",
    "            weight_data = np.delete(weights,slice(c*i,(c+1)*i,1),axis=0)\n",
    "            weight_data = weight_data[0:len(weight_data)-8]\n",
    "            \n",
    "    else:\n",
    "        val_data = val_data[0:len(val_data)-8] #Eliminating the data points which may affect future datapoints\n",
    "        data_1=dataset[0:(c*i)-8,:] \n",
    "        data_2=dataset[(c+1)*i:N,:] \n",
    "        train_data = np.concatenate((data_1,data_2),axis=0)   \n",
    "        if(flag == True):\n",
    "            wdata_1 = weights[0:(c*i)-8]\n",
    "            wdata_2 = weights[(c+1)*i:N]\n",
    "            weight_data = np.concatenate((wdata_1, wdata_2), axis=0)\n",
    "            \n",
    "    if(flag == False):\n",
    "        return train_data, val_data\n",
    "    else:\n",
    "        return train_data, val_data, weight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a71e0",
   "metadata": {
    "id": "a15a71e0"
   },
   "outputs": [],
   "source": [
    "def model_test(model, test_data):\n",
    "    '''\n",
    "    Function to test the ML model on the test dataset\n",
    "    \n",
    "    Parameters:\n",
    "    model: Model fitted onto the train data\n",
    "    test_data: Dataset to test on\n",
    "    \n",
    "    Return:\n",
    "    Confusion Matrix for test data\n",
    "    '''\n",
    "    test = test_data[:,0:-1]\n",
    "    y_test = test_data[:,-1].astype(int)\n",
    "    \n",
    "    y_pred = model.predict(test) #predicting accuracy on test data\n",
    "    \n",
    "    test_accuracy, test_f1 = performance_measure(y_pred, y_test)\n",
    "    print(\"Test accuracy is\", round_off_values(test_accuracy)) \n",
    "    print(\"Test f1 score is\", round_off_values(test_f1))\n",
    "    plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf849fa5",
   "metadata": {
    "id": "bf849fa5"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1f3f3",
   "metadata": {
    "id": "adf1f3f3"
   },
   "outputs": [],
   "source": [
    "def hyperparameters_opt_svm(X_train, y_train, X_val, y_val,range_C, range_kernel, range_gamma):\n",
    "    '''\n",
    "    Function to determine the optimal hyperparameters for the SVM kernel for the given partition\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Features of train dataset from the given partition\n",
    "    y_train: Class labels of train dataset from the given partition\n",
    "    X_val: Features of validation dataset from the given partition\n",
    "    y_val: Class labels of validation dataset from the given partition\n",
    "    range_C: List of values of the regularization parameter\n",
    "    range_kernel: List of values of the kernel parameter\n",
    "    range_gamma: List of values of the gamma parameter\n",
    "    \n",
    "    Return:\n",
    "    score_list: F1 scores for each hyperparameter combination\n",
    "    train_accuracy: Accuracy on train dataset for the given partition\n",
    "    train_f1: F1 score on train dataset for the given partition\n",
    "    val_accuracy: Accuracy on validation dataset for the given partition\n",
    "    val_f1: F1 score on validation dataset for the given partition\n",
    "    '''\n",
    "    \n",
    "    X_train=X_train.astype(float)\n",
    "    y_train=y_train.astype(float)\n",
    "    X_val=X_val.astype(float)\n",
    "    y_val=y_val.astype(float)\n",
    "\n",
    "    #Lists used to determine train/val performance measures during cross validation\n",
    "    train_acc = []\n",
    "    train_f_1 = []\n",
    "    val_acc  =[]\n",
    "    val_f_1 = []\n",
    "    \n",
    "    score_list=np.zeros((len(range_C),len(range_kernel),len(range_gamma))) #matrix used to store F1 score across hyperparameters\n",
    "    \n",
    "    for i, C in enumerate(range_C):\n",
    "        for j, algo in enumerate(range_kernel):\n",
    "            for k, gamma in enumerate(range_gamma):\n",
    "\n",
    "                model = svm.SVC(kernel = algo, C = C, gamma = gamma, class_weight = 'balanced')\n",
    "                model.fit(X_train, y_train) #fitting the SVM model on train data\n",
    "                y_pred = model.predict(X_train) #predicting accuracy on train data\n",
    "                \n",
    "                train_accuracy, train_f1 = performance_measure(y_pred, y_train)\n",
    "                train_acc.append(train_accuracy)\n",
    "                train_f_1.append(train_f1)\n",
    "                \n",
    "                y_pred=model.predict(X_val) #predicting accuracy on val data\n",
    "    \n",
    "                val_accuracy, val_f1 = performance_measure(y_pred, y_val)\n",
    "                val_acc.append(val_accuracy)\n",
    "                val_f_1.append(val_f1)\n",
    "                \n",
    "                f1 = f1_score(y_val, y_pred)\n",
    "                score_list[i][j][k] = f1 #Storing the F1 score for the specific hyperparameter combination\n",
    "\n",
    "    #Obtaining the mean performance metrics for the data partition\n",
    "    train_accuracy = sum(train_acc)/len(train_acc)\n",
    "    train_f1 = sum(train_f_1)/len(train_f_1)\n",
    "    val_accuracy = sum(val_acc)/len(val_acc)\n",
    "    val_f1 = sum(val_f_1)/len(val_f_1)\n",
    "    return score_list, train_accuracy, train_f1, val_accuracy, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb182d26",
   "metadata": {
    "id": "cb182d26"
   },
   "outputs": [],
   "source": [
    "def svm_model_train(dataset, total_batches, weights = 0):\n",
    "    '''\n",
    "    Function to train the SVM model on the train dataset\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: input dataset for training\n",
    "    total_batches: Number of batches to determine division of train/val data\n",
    "    \n",
    "    Return:\n",
    "    optimal_model: SVM Model fitted onto the train data\n",
    "    '''\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    #Lists used to determine train/val performance measures during cross validation\n",
    "    train_acc = []\n",
    "    train_f1 = []\n",
    "    val_acc = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    #Range of values of hyperparameters for SVM\n",
    "    range_C=np.array([0.01, 0.5, 0.1, 1, 2, 5, 10, 50, 100, 500, 1000])\n",
    "    range_kernel = np.array(['linear', 'poly','rbf', 'sigmoid'])\n",
    "    range_gamma=np.array([0.001, 0.1, 0.2, 2, 10])\n",
    "\n",
    "    score_matrix = np.zeros((total_batches,len(range_C),len(range_kernel), len(range_gamma))) #matrix used to store F1 score across hyperparameters and batches\n",
    "    final_score = np.zeros((len(range_C), len(range_kernel), len(range_gamma))) #matrix used to store F1 score across hyperparameters by averaging across batches\n",
    "                   \n",
    "    while count<total_batches:\n",
    "        n=len(dataset)/total_batches\n",
    "        train_data, val_data = cross_validation(count, dataset, n, False, 0)\n",
    "        \n",
    "        \n",
    "        X_train=train_data[:,0:-1]\n",
    "        y_train=train_data[:,-1]\n",
    "        X_val=val_data[:,0:-1]\n",
    "        y_val=val_data[:,-1]\n",
    "        \n",
    "        score_matrix[count], t_acc, t_f1, v_acc, v_f1 = hyperparameters_opt_svm(X_train, y_train, X_val, y_val, range_C, range_kernel, range_gamma)\n",
    "        \n",
    "        train_acc.append(t_acc)\n",
    "        train_f1.append(t_f1)\n",
    "        val_acc.append(v_acc)\n",
    "        val_f1.append(v_f1)\n",
    "        \n",
    "        count+=1\n",
    "  \n",
    "    for i in range(len(range_C)):\n",
    "        for j in range(len(range_kernel)):\n",
    "            for k in range(len(range_gamma)):\n",
    "                final_score[i,j,k]=np.mean(score_matrix[:,i,j,k]) #Calculating the average across data partitions\n",
    "\n",
    "    print_acc_val(train_acc,train_f1,val_acc,val_f1)\n",
    "    \n",
    "    max_index = np.unravel_index(final_score.argmax(), final_score.shape)\n",
    "    optimal_C = range_C[max_index[0]]\n",
    "    optimal_kernel = range_kernel[max_index[1]]\n",
    "    optimal_gamma = range_gamma[max_index[2]]\n",
    "    \n",
    "    print(\"optimal_C:\",optimal_C)\n",
    "    print(\"optimal kernel:\",optimal_kernel)\n",
    "    print(\"optimal_gamma:\",optimal_gamma)\n",
    "    \n",
    "    optimal_model = svm.SVC(kernel=optimal_kernel, C=optimal_C, gamma=optimal_gamma, class_weight = 'balanced')\n",
    "    \n",
    "    training_dataset=dataset[:,0:-1]\n",
    "    training_dataset=training_dataset.astype(float)\n",
    "    class_label=dataset[:,-1]\n",
    "    class_label=class_label.astype(float)\n",
    "    \n",
    "    optimal_model.fit(training_dataset,class_label)\n",
    "    y_pred = optimal_model.predict(training_dataset) #predicting accuracy on entire train data\n",
    "    final_train_accuracy, final_train_f1 = performance_measure(y_pred, class_label)\n",
    "    print(\"Final Train accuracy is\", round_off_values(final_train_accuracy))\n",
    "    print(\"Final Train f1 is\", round_off_values(final_train_f1))\n",
    "\n",
    "    return optimal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b92a78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "a5b92a78",
    "outputId": "16e95df7-7d10-4c3a-d1bb-e18d797239b9"
   },
   "outputs": [],
   "source": [
    "#Executing the SVM model\n",
    "\n",
    "optimal_svm_model=svm_model_train(train_mov_np, 6)\n",
    "model_test(optimal_svm_model,test_mov_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ddf82",
   "metadata": {
    "id": "239ddf82"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4e561",
   "metadata": {
    "id": "a0a4e561"
   },
   "outputs": [],
   "source": [
    "def hyperparameters_opt_NB(X_train, y_train, X_val, y_val, range_alpha, weight):\n",
    "    '''\n",
    "    Function to determine the optimal hyperparameters for the Naive Bayes model for the given partition\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Features of train dataset from the given partition\n",
    "    y_train: Class labels of train dataset from the given partition\n",
    "    X_val: Features of validation dataset from the given partition\n",
    "    y_val: Class labels of validation dataset from the given partition\n",
    "    range_alpha: List of values of the regularization parameter\n",
    "    weight: List of weights for each sample\n",
    "    \n",
    "    Return:\n",
    "    score_list: F1 scores for each hyperparameter combination\n",
    "    train_accuracy: Accuracy on train dataset for the given partition\n",
    "    train_f1: F1 score on train dataset for the given partition\n",
    "    val_accuracy: Accuracy on validation dataset for the given partition\n",
    "    val_f1: F1 score on validation dataset for the given partition\n",
    "    '''\n",
    "    \n",
    "    X_train=X_train.astype(float)\n",
    "    y_train=y_train.astype(float)\n",
    "    X_val=X_val.astype(float)\n",
    "    y_val=y_val.astype(float)\n",
    "    \n",
    "    score_list=np.zeros(len(range_alpha)) #matrix used to store F1 score across hyperparameters\n",
    "    \n",
    "    #Lists used to determine train/val performance measures during cross validation\n",
    "    train_acc = []\n",
    "    train_f_1 = []\n",
    "    val_acc  =[]\n",
    "    val_f_1 = []\n",
    "    \n",
    "    for i, alpha_val in enumerate(range_alpha):\n",
    "        \n",
    "        model = ComplementNB(alpha = alpha_val)\n",
    "        model.fit(np.absolute(X_train), y_train, weight) #fitting the Naive Bayes model on train data \n",
    "        y_pred = model.predict(X_train) #predicting accuracy on train data\n",
    "        \n",
    "        train_accuracy, train_f1 = performance_measure(y_pred, y_train)\n",
    "        train_acc.append(train_accuracy)\n",
    "        train_f_1.append(train_f1)\n",
    "\n",
    "        y_pred = model.predict(X_val) #predicting accuracy on val data\n",
    "        val_accuracy, val_f1 = performance_measure(y_pred, y_val)\n",
    "        val_acc.append(val_accuracy)\n",
    "        val_f_1.append(val_f1)\n",
    "        \n",
    "        f1 = f1_score(y_val, y_pred) \n",
    "        score_list[i] = f1 #Storing the F1 score for the specific hyperparameter combination\n",
    "\n",
    "    #Obtaining the mean performance metrics for the data partition\n",
    "    train_accuracy = sum(train_acc)/len(train_acc)\n",
    "    train_f1 = sum(train_f_1)/len(train_f_1)\n",
    "    val_accuracy = sum(val_acc)/len(val_acc)\n",
    "    val_f1 = sum(val_f_1)/len(val_f_1)\n",
    "    \n",
    "    return score_list, train_accuracy, train_f1, val_accuracy, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a4061",
   "metadata": {
    "id": "907a4061"
   },
   "outputs": [],
   "source": [
    "def NB_model_train(dataset, total_batches):\n",
    "    '''\n",
    "    Function to train the Naive Bayes model on the train dataset\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: Dataset to train on\n",
    "    total_batches: Number of batches to determine division of train/val data\n",
    "    \n",
    "    Return:\n",
    "    optimal_model: Naive Bayes Model fitted onto the train data\n",
    "    '''\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    #Weights that are inversely proportional to the class size\n",
    "    weights = np.zeros(len(dataset))\n",
    "    weights[train_mov_np[:, -1] == 0] = 1/69\n",
    "    weights[train_mov_np[:, -1] == 1] = 1/115\n",
    "    \n",
    "    #Lists used to determine train/val performance measures during cross validation\n",
    "    train_acc = []\n",
    "    train_f1 = []\n",
    "    val_acc = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    #Range of values of hyperparameters for Naive Bayes\n",
    "    range_alpha= np.array([0.005, 0.01, 0.1, 0.5, 1.0, 10.0])\n",
    "\n",
    "    score_matrix = np.zeros((total_batches,len(range_alpha))) #matrix used to store F1 score across hyperparameters and batches\n",
    "    final_score = np.zeros(len(range_alpha)) #matrix used to store F1 score across hyperparameters by averaging across batches\n",
    "    \n",
    "    while count<total_batches:\n",
    "        n=len(dataset)/total_batches\n",
    "        train_data, val_data, w = cross_validation(count, dataset, n, True, weights)\n",
    "        \n",
    "        X_train=train_data[:,0:-1]\n",
    "        y_train=train_data[:,-1]\n",
    "        X_val=val_data[:,0:-1]\n",
    "        y_val=val_data[:,-1]\n",
    "        \n",
    "        score_matrix[count], t_acc, t_f1, v_acc, v_f1 = hyperparameters_opt_NB(X_train, y_train, X_val, y_val, range_alpha, w)\n",
    "\n",
    "        train_acc.append(t_acc)\n",
    "        train_f1.append(t_f1)\n",
    "        val_acc.append(v_acc)\n",
    "        val_f1.append(v_f1)\n",
    "        \n",
    "        count+=1\n",
    "    \n",
    "    for i in range(len(range_alpha)):\n",
    "        final_score[i] = np.mean(score_matrix[:,i]) #Calculating the average across data partitions\n",
    "        \n",
    "    print_acc_val(train_acc,train_f1,val_acc,val_f1)\n",
    "    \n",
    "            \n",
    "    max_index=np.unravel_index(final_score.argmax(), final_score.shape)\n",
    "    optimal_alpha=range_alpha[max_index[0]]\n",
    "\n",
    "    print(\"Optimal Alpha is\", optimal_alpha)\n",
    "  \n",
    "    optimal_model = ComplementNB(alpha = optimal_alpha)\n",
    "\n",
    "    training_dataset=dataset[:,0:-1]\n",
    "    training_dataset=training_dataset.astype(float)\n",
    "    class_label=dataset[:,-1]\n",
    "    class_label=class_label.astype(float)\n",
    "    \n",
    "    optimal_model.fit(np.absolute(training_dataset), class_label, weights)\n",
    "    y_pred = optimal_model.predict(training_dataset) #predicting accuracy on entire train data\n",
    "    final_train_accuracy, final_train_f1 = performance_measure(y_pred, class_label)\n",
    "    print(\"Final Train Accuracy is\", round_off_values(final_train_accuracy))\n",
    "    print(\"Final Train F1 Score is\", round_off_values(final_train_f1))\n",
    "\n",
    "    return optimal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ediklcku2VCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "ediklcku2VCq",
    "outputId": "fdca3b05-7f66-40a7-8fee-7a940283660b"
   },
   "outputs": [],
   "source": [
    "#Executing the Naive Bayes model\n",
    "\n",
    "optimal_nb_model = NB_model_train(train_mov_np,6)        \n",
    "model_test(optimal_nb_model,test_mov_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbf08a1",
   "metadata": {
    "id": "dbbf08a1"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab5f18",
   "metadata": {
    "id": "01ab5f18"
   },
   "outputs": [],
   "source": [
    "def hyperparameters_opt_log_reg(X_train, y_train, X_val, y_val, range_C, range_solver):\n",
    "    '''\n",
    "    Function to determine the optimal hyperparameters for the Logistic Regression model for the given partition\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Features of train dataset from the given partition\n",
    "    y_train: Class labels of train dataset from the given partition\n",
    "    X_val: Features of validation dataset from the given partition\n",
    "    y_val: Class labels of validation dataset from the given partition\n",
    "    range_C: List of values of the regularization parameter\n",
    "    range_solver: List of values of algorithm to use in optimization\n",
    "    \n",
    "    Return:\n",
    "    score_list: F1 scores for each hyperparameter combination\n",
    "    train_accuracy: Accuracy on train dataset for the given partition\n",
    "    train_f1: F1 score on train dataset for the given partition\n",
    "    val_accuracy: Accuracy on validation dataset for the given partition\n",
    "    val_f1: F1 score on validation dataset for the given partition\n",
    "    '''\n",
    "    \n",
    "    X_train=X_train.astype(float)\n",
    "    y_train=y_train.astype(float)\n",
    "    X_val=X_val.astype(float)\n",
    "    y_val=y_val.astype(float)\n",
    "\n",
    "    #Lists used to determine train/val performance measures during cross validation\n",
    "    train_acc = []\n",
    "    train_f_1 = []\n",
    "    val_acc  =[]\n",
    "    val_f_1 = []\n",
    "    \n",
    "    score_list=np.zeros((len(range_C), len(range_solver))) #matrix used to store F1 score across hyperparameters\n",
    "    \n",
    "    for i,c in enumerate(range_C):\n",
    "        for j,algo in enumerate(range_solver):\n",
    "\n",
    "            model = LogisticRegression(C=c,solver=algo, max_iter=200, penalty = 'l2', class_weight = 'balanced')\n",
    "            model.fit(X_train, y_train) #fitting the Logistic Regression model on train data \n",
    "            y_pred = model.predict(X_train) #predicting accuracy on train data\n",
    "            \n",
    "            train_accuracy, train_f1 = performance_measure(y_pred, y_train)\n",
    "            train_acc.append(train_accuracy)\n",
    "            train_f_1.append(train_f1)\n",
    "\n",
    "            y_pred = model.predict(X_val) #predicting accuracy on val data\n",
    "            val_accuracy, val_f1 = performance_measure(y_pred, y_val)\n",
    "            val_acc.append(val_accuracy)\n",
    "            val_f_1.append(val_f1)\n",
    "\n",
    "            f1 = f1_score(y_val, y_pred) \n",
    "            score_list[i][j] = f1 #Storing the F1 score for the specific hyperparameter combination\n",
    "\n",
    "    #Obtaining the mean performance metrics for the data partition\n",
    "    train_accuracy = sum(train_acc)/len(train_acc)\n",
    "    train_f1 = sum(train_f_1)/len(train_f_1)\n",
    "    val_accuracy = sum(val_acc)/len(val_acc)\n",
    "    val_f1 = sum(val_f_1)/len(val_f_1)\n",
    "    \n",
    "    return score_list, train_accuracy, train_f1, val_accuracy, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fOpDCtK72VE7",
   "metadata": {
    "id": "fOpDCtK72VE7"
   },
   "outputs": [],
   "source": [
    "def log_reg_model_train(dataset,total_batches):\n",
    "    '''\n",
    "    Function to train the Logistic Regression model on the train dataset\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: Dataset to train on\n",
    "    total_batches: Number of batches to determine division of train/val data\n",
    "    \n",
    "    Return:\n",
    "    optimal_model: Logistic Regression Model fitted onto the train data\n",
    "    '''\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    #Lists used to determine train/val performance measures during cross validation\n",
    "    train_acc = []\n",
    "    train_f1 = []\n",
    "    val_acc = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    #Range of values of hyperparameters for Logistic Regression\n",
    "    range_C=np.array([100, 10, 1.0, 0.1, 0.01])\n",
    "    range_solver = np.array(['newton-cg','lbfgs','liblinear'])\n",
    "\n",
    "    score_matrix = np.zeros((total_batches,len(range_C), len(range_solver))) #matrix used to store F1 score across hyperparameters and batches\n",
    "    final_score = np.zeros((len(range_C),len(range_solver))) #matrix used to store F1 score across hyperparameters by averaging across batches\n",
    "                   \n",
    "    while count<total_batches:\n",
    "        n=len(dataset)/total_batches\n",
    "        train_data,val_data=cross_validation(count, dataset, n, False, 0)\n",
    "        \n",
    "        \n",
    "        X_train=train_data[:,0:-1]\n",
    "        y_train=train_data[:,-1]\n",
    "        X_val=val_data[:,0:-1]\n",
    "        y_val=val_data[:,-1]\n",
    "        \n",
    "        score_matrix[count], t_acc, t_f1, v_acc, v_f1 = hyperparameters_opt_log_reg(X_train, y_train, X_val, y_val, range_C, range_solver)\n",
    "        \n",
    "        train_acc.append(t_acc)\n",
    "        train_f1.append(t_f1)\n",
    "        val_acc.append(v_acc)\n",
    "        val_f1.append(v_f1)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "    for i in range(len(range_C)):\n",
    "        for j in range(len(range_solver)):\n",
    "            final_score[i][j]=np.mean(score_matrix[:,i,j]) #Calculating the average across data partitions\n",
    "\n",
    "    print_acc_val(train_acc,train_f1,val_acc,val_f1)\n",
    "\n",
    "    max_index = np.unravel_index(final_score.argmax(), final_score.shape)\n",
    "    optimal_C = range_C[max_index[0]]\n",
    "    optimal_solver = range_solver[max_index[1]]\n",
    "    \n",
    "    print(\"Optimal value of C is\",optimal_C)\n",
    "    print(\"Optimal solver is\",optimal_solver)\n",
    "    \n",
    "    optimal_model = LogisticRegression(C=optimal_C,solver=optimal_solver, max_iter=200, penalty = 'l2', class_weight = 'balanced')\n",
    "    \n",
    "    training_dataset=dataset[:,0:-1]\n",
    "    training_dataset=training_dataset.astype(float)\n",
    "    class_label=dataset[:,-1]\n",
    "    class_label=class_label.astype(float)\n",
    "    \n",
    "    optimal_model.fit(training_dataset,class_label )\n",
    "    y_pred = optimal_model.predict(training_dataset) #predicting accuracy on entire train data\n",
    "    final_train_accuracy, final_train_f1 = performance_measure(y_pred, class_label)\n",
    "    print(\"Final Train Accuracy is\", round_off_values(final_train_accuracy))\n",
    "    print(\"Final Train F1 Score is\", round_off_values(final_train_f1))\n",
    "    \n",
    "    return optimal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TowoXO7n2VHh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "TowoXO7n2VHh",
    "outputId": "1a6fc339-b7a4-44c1-83f1-cba3fab5b312"
   },
   "outputs": [],
   "source": [
    "optimal_log_reg_model = log_reg_model_train(train_mov_np,7)\n",
    "model_test(optimal_log_reg_model, test_mov_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820d201",
   "metadata": {
    "id": "3820d201"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec034cd9",
   "metadata": {
    "id": "ec034cd9"
   },
   "outputs": [],
   "source": [
    "def hyperparameters_opt_dec_tree(X_train, y_train, X_val, y_val, range_min_samples_leaf, range_sample_split):\n",
    "    '''\n",
    "    Function to determine the optimal hyperparameters for the Decision tree model for the given partition\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Features of train dataset from the given partition\n",
    "    y_train: Class labels of train dataset from the given partition\n",
    "    X_val: Features of validation dataset from the given partition\n",
    "    y_val: Class labels of validation dataset from the given partition\n",
    "    range_min_samples_leaf: List of values of the minimum number of samples at a leaf node\n",
    "    range_sample_split: List of values of minimum number of samples required to split an internal node\n",
    "    \n",
    "    Return:\n",
    "    score_list: F1 scores for each hyperparameter combination\n",
    "    train_accuracy: Accuracy on train dataset for the given partition\n",
    "    train_f1: F1 score on train dataset for the given partition\n",
    "    val_accuracy: Accuracy on validation dataset for the given partition\n",
    "    val_f1: F1 score on validation dataset for the given partition\n",
    "    '''\n",
    "    \n",
    "    X_train=X_train.astype(float)\n",
    "    y_train=y_train.astype(float)\n",
    "    X_val=X_val.astype(float)\n",
    "    y_val=y_val.astype(float)\n",
    "\n",
    "    #Lists used to determine train/val performance measures during cross validation\n",
    "    train_acc = []\n",
    "    train_f_1 = []\n",
    "    val_acc  =[]\n",
    "    val_f_1 = []\n",
    "    \n",
    "    score_list=np.zeros((len(range_min_samples_leaf),len(range_sample_split))) #matrix used to store F1 score across hyperparameters\n",
    "    \n",
    "    for i,leaf in enumerate(range_min_samples_leaf):\n",
    "        for j,sample_split in enumerate(range_sample_split):\n",
    "\n",
    "            model = tree.DecisionTreeClassifier(min_samples_leaf=leaf, min_samples_split=sample_split, criterion='gini', class_weight = 'balanced')\n",
    "            model.fit(X_train, y_train) #fitting the Logistic Regression model on train data \n",
    "            y_pred = model.predict(X_train) #predicting accuracy on train data\n",
    "            \n",
    "            train_accuracy, train_f1 = performance_measure(y_pred, y_train)\n",
    "            train_acc.append(train_accuracy)\n",
    "            train_f_1.append(train_f1)\n",
    "\n",
    "            y_pred = model.predict(X_val) #predicting accuracy on val data\n",
    "            val_accuracy, val_f1 = performance_measure(y_pred, y_val)\n",
    "            val_acc.append(val_accuracy)\n",
    "            val_f_1.append(val_f1)\n",
    "        \n",
    "            f1 = f1_score(y_val, y_pred)\n",
    "            score_list[i][j] = f1 #Storing the F1 score for the specific hyperparameter combination\n",
    "\n",
    "    #Obtaining the mean performance metrics for the data partition\n",
    "    train_accuracy = sum(train_acc)/len(train_acc)\n",
    "    train_f1 = sum(train_f_1)/len(train_f_1)\n",
    "    val_accuracy = sum(val_acc)/len(val_acc)\n",
    "    val_f1 = sum(val_f_1)/len(val_f_1)\n",
    "    \n",
    "    return score_list, train_accuracy, train_f1, val_accuracy, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c960e04",
   "metadata": {
    "id": "9c960e04"
   },
   "outputs": [],
   "source": [
    "def decision_tree_model_train(dataset,total_batches):\n",
    "    '''\n",
    "    Function to train the Decision Tree model on the train dataset\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: Dataset to train on\n",
    "    total_batches: Number of batches to determine division of train/val data\n",
    "    \n",
    "    Return:\n",
    "    optimal_model: Decision Tree Model fitted onto the train data\n",
    "    '''\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    #Lists used to determine train/val performance measures during cross validation\n",
    "    train_acc = []\n",
    "    train_f1 = []\n",
    "    val_acc = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    #Range of values of hyperparameters for Decision Tree\n",
    "    range_min_samples_leaf = np.array([2, 3, 4, 5, 6, 7])\n",
    "    range_sample_split = np.array([2,3,4,5,6,7, 8, 9])\n",
    "\n",
    "    score_matrix = np.zeros((total_batches,len(range_min_samples_leaf),len(range_sample_split))) #matrix used to store F1 score across hyperparameters and batches\n",
    "    final_score = np.zeros((len(range_min_samples_leaf),len(range_sample_split))) #matrix used to store F1 score across hyperparameters by averaging across batches\n",
    "                   \n",
    "    while count<total_batches:\n",
    "        n=len(dataset)/total_batches\n",
    "        train_data,val_data=cross_validation(count, dataset, n, False, 0)\n",
    "                \n",
    "        X_train=train_data[:,0:-1]\n",
    "        y_train=train_data[:,-1]\n",
    "        X_val=val_data[:,0:-1]\n",
    "        y_val=val_data[:,-1]\n",
    "        \n",
    "        score_matrix[count], t_acc, t_f1, v_acc, v_f1=hyperparameters_opt_dec_tree(X_train, y_train, X_val, y_val, range_min_samples_leaf, range_sample_split)\n",
    "        \n",
    "        train_acc.append(t_acc)\n",
    "        train_f1.append(t_f1)\n",
    "        val_acc.append(v_acc)\n",
    "        val_f1.append(v_f1)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "    for i in range(len(range_min_samples_leaf)):\n",
    "        for j in range(len(range_sample_split)):\n",
    "            final_score[i,j] = np.mean(score_matrix[:,i,j]) #Calculating the average across data partitions\n",
    "\n",
    "    print_acc_val(train_acc,train_f1,val_acc,val_f1)\n",
    "    \n",
    "    max_index=np.unravel_index(final_score.argmax(), final_score.shape)\n",
    "    optimal_leaf = range_min_samples_leaf[max_index[0]]\n",
    "    optimal_split = range_sample_split[max_index[1]]\n",
    "    \n",
    "    print(\"Optimal number of minimum samples of leaf is\", optimal_leaf)\n",
    "    print(\"Optimal number of sample splits is\", optimal_split)\n",
    "    \n",
    "    optimal_model = tree.DecisionTreeClassifier(min_samples_leaf=optimal_leaf, min_samples_split=optimal_split, criterion='gini', class_weight = 'balanced')\n",
    "   \n",
    "    training_dataset=dataset[:,0:-1]\n",
    "    training_dataset=training_dataset.astype(float)\n",
    "    class_label=dataset[:,-1]\n",
    "    class_label=class_label.astype(float)\n",
    "    \n",
    "    optimal_model.fit(training_dataset,class_label )\n",
    "    y_pred = optimal_model.predict(training_dataset) #predicting accuracy on entire train data\n",
    "    final_train_accuracy, final_train_f1 = performance_measure(y_pred, class_label)\n",
    "    print(\"Final Train Accuracy is\", round_off_values(final_train_accuracy))\n",
    "    print(\"Final Train F1 Score is\", round_off_values(final_train_f1))\n",
    "\n",
    "    return optimal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de36c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "14de36c1",
    "outputId": "8e7f0278-1d43-4e36-9095-f77cb984b9a0"
   },
   "outputs": [],
   "source": [
    "optimal_decision_tree_model = decision_tree_model_train(train_mov_np,6)\n",
    "model_test(optimal_decision_tree_model, test_mov_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GGCq4qLvAT9T",
   "metadata": {
    "id": "GGCq4qLvAT9T"
   },
   "source": [
    "## ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2nu_OBBtcLCJ",
   "metadata": {
    "id": "2nu_OBBtcLCJ"
   },
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    '''\n",
    "    Function to create features from the date column of the data frame\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Function to generate the structure of neural network\n",
    "        '''\n",
    "        super(ANN, self).__init__()\n",
    "        self.net=nn.Sequential(# using Sequential container\n",
    "\n",
    "        nn.Linear(8, 6),# input layer\n",
    "        nn.ReLU(),# activation\n",
    "        nn.Linear(6, 3),# hidden layer 1\n",
    "        nn.ReLU(),# activation\n",
    "        nn.Linear(3, 1),# hidden layer 2\n",
    "        nn.Sigmoid()# output layer\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        '''\n",
    "        Function to generate the output of the neural network\n",
    "        Parameters:\n",
    "        x: input\n",
    "\n",
    "        Return:\n",
    "        output: output of the neural network\n",
    "        '''\n",
    "        output= self.net(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I_4_BOYC0jjl",
   "metadata": {
    "id": "I_4_BOYC0jjl"
   },
   "outputs": [],
   "source": [
    "def classification_model(learning_rate,wt_decay):\n",
    "    '''\n",
    "    Function to create a column with moving average of temperature from the temperature column of the data frame\n",
    "    \n",
    "    Parameters:\n",
    "    df: input data frame\n",
    "    learning_rate: learning rate\n",
    "    wt_decay: weight decay\n",
    "    \n",
    "    Return:\n",
    "    model: created model\n",
    "    optimizer: Adam optimizer\n",
    "    '''\n",
    "    model = ANN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wt_decay)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PZ2vXIW10jly",
   "metadata": {
    "id": "PZ2vXIW10jly"
   },
   "outputs": [],
   "source": [
    "def convert_data(x):\n",
    "    '''\n",
    "    Function to create a tensor from the input numpy array\n",
    "    Parameters:\n",
    "    x: input numpy array\n",
    "\n",
    "    Return:\n",
    "    tensor form of the input numpy array \n",
    "    '''\n",
    "    return torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CdKBbjEC0jqq",
   "metadata": {
    "id": "CdKBbjEC0jqq"
   },
   "outputs": [],
   "source": [
    "def weighted_binary_cross_entropy(output, target):\n",
    "    '''\n",
    "    Function to calculate the loss function values using a custom loss function for imbalanced dataset\n",
    "    \n",
    "    Parameters:\n",
    "    output: actual label\n",
    "    target: predicted label\n",
    "    Return:\n",
    "    df: updated data frame\n",
    "    '''\n",
    "   \n",
    "    weights=torch.FloatTensor([1/115,1/69])\n",
    "    if weights is not None:\n",
    "        assert len(weights) == 2\n",
    "        loss = weights[1] * (target * torch.log(output)) + \\\n",
    "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "\n",
    "    return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Gc6XMtg0jva",
   "metadata": {
    "id": "-Gc6XMtg0jva"
   },
   "outputs": [],
   "source": [
    "def hyperparameters_opt_adam_ANN(X_train, y_train, X_val, y_val,range_learning_rate,range_weight_decay,num_epochs):\n",
    "    '''\n",
    "    Function to perform hyperparameter tuning for weight decay and learning rate values\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: Features of train dataset from the given partition\n",
    "    y_train: Class labels of train dataset from the given partition\n",
    "    X_val: Features of validation dataset from the given partition\n",
    "    y_val: Class labels of validation dataset from the given partition\n",
    "    range_learning_rate: List of values of the learning rate parameter\n",
    "    range_weight_decay: List of values of the weight decay parameter\n",
    "    num_epochs: total number of epochs\n",
    "    \n",
    "    Return:\n",
    "    score_list: F1 scores for each hyperparameter combination\n",
    "    train_accuracy: Accuracy on train dataset for the given partition\n",
    "    train_f1: F1 score on train dataset for the given partition\n",
    "    val_accuracy: Accuracy on validation dataset for the given partition\n",
    "    val_f1: F1 score on validation dataset for the given partition\n",
    "    '''\n",
    "   \n",
    "    score_list=np.zeros((len(range_learning_rate),len(range_weight_decay)))\n",
    "    train_accuracy=[]\n",
    "    validation_accuracy=[]\n",
    "    train_f1_score=[] \n",
    "    validation_f1_score=[]\n",
    "    for i,learning_rate in enumerate(range_learning_rate):\n",
    "            for j,m in enumerate(range_weight_decay):\n",
    "                model, optimizer=classification_model(learning_rate,m)\n",
    "                epoch_val_f1=[]\n",
    "                epoch_train_f1=[]\n",
    "                epoch_train_acc=[]\n",
    "                epoch_val_acc=[]\n",
    "                for epoch in range(num_epochs):\n",
    "                                y_pred = model(X_train)\n",
    "                                y_pred = torch.squeeze(y_pred)\n",
    "                                train_loss = weighted_binary_cross_entropy(y_pred, y_train)\n",
    "\n",
    "                                if (epoch+1)%10==0:# after every 10 epochs are completed\n",
    "                                    y_pred=y_pred.detach().numpy()# detach and convert to numpy\n",
    "                                    y_pred = np.where(y_pred>0.5, 1, 0)# convert probability to target vector\n",
    "                                    train_acc, train_f1=performance_measure(y_pred, y_train)\n",
    "                                    y_val_pred = model(X_val)# finding predicted label for validation set\n",
    "                                    y_val_pred = torch.squeeze(y_val_pred)\n",
    "                                    val_loss=weighted_binary_cross_entropy(y_val_pred, y_val)\n",
    "                                    y_val_pred=y_val_pred.detach().numpy()# detach and convert to numpy\n",
    "                                    y_val_pred = np.where(y_val_pred>0.5, 1, 0)# convert probability to target vector\n",
    "                                    val_acc, val_f1=performance_measure(y_val_pred, y_val)\n",
    "                                    epoch_val_f1.append(val_f1)\n",
    "                                    epoch_val_acc.append(val_acc)\n",
    "                                    epoch_train_f1.append(train_f1)\n",
    "                                    epoch_train_acc.append(train_acc)\n",
    "                                optimizer.zero_grad()\n",
    "                                train_loss.backward()\n",
    "                                optimizer.step()\n",
    "\n",
    "            train_accuracy.extend(epoch_train_acc) \n",
    "            validation_accuracy.extend(epoch_val_acc) \n",
    "            train_f1_score.extend(epoch_train_f1) \n",
    "            validation_f1_score.extend(epoch_val_f1) \n",
    "\n",
    "            score_list[i][j]=sum(epoch_val_f1)/len(epoch_val_f1)# stores the f1 score for each hyperparameter combination\n",
    "    #Obtaining the mean performance metrics for the data partition\n",
    "    train_accuracy_final = sum(train_accuracy)/len(train_accuracy)\n",
    "    train_f1_final = sum(train_f1_score)/len(train_f1_score)\n",
    "    val_accuracy_final = sum(validation_accuracy)/len(validation_accuracy)\n",
    "    val_f1_final = sum(validation_f1_score)/len(validation_f1_score)\n",
    "    \n",
    "    return score_list,train_accuracy_final,train_f1_final,val_accuracy_final,val_f1_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P_67AiwZ0yep",
   "metadata": {
    "id": "P_67AiwZ0yep"
   },
   "outputs": [],
   "source": [
    "\n",
    "def ann_model_adam_train(dataset,total_batches):\n",
    "    '''\n",
    "    Function to create a column with moving average of temperature from the temperature column of the data frame\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: input data to train the model on\n",
    "    total_batches: number of batches to divide the dataset in\n",
    "    Return:\n",
    "    df: updated data frame\n",
    "    '''\n",
    "    count=0\n",
    "    num_epochs=5000# number of epochs\n",
    "    param_range_weight_decay=np.array([0.0001,0.001,0.005,0.01,0.05,0.1,0.5])#list of weight decay\n",
    "    param_range_learning_rate=np.array([0.0001,0.001,0.01,0.1,0.5])# list of learning rate\n",
    "    score_matrix=np.zeros((total_batches,len(param_range_learning_rate),len(param_range_weight_decay)))\n",
    "    final=np.zeros((len(param_range_learning_rate),len(param_range_weight_decay)))\n",
    "    train_acc = []\n",
    "    train_f1 = []\n",
    "    val_acc = []\n",
    "    val_f1 = []            \n",
    "    while count<total_batches:# cross validation loop\n",
    "        n=len(dataset)/total_batches\n",
    "        train_data,val_data=cross_validation(count,dataset,n,False,0)\n",
    "        X_train=convert_data(train_data[:,0:-1])\n",
    "        y_train=convert_data(train_data[:,-1])\n",
    "        X_val=convert_data(val_data[:,0:-1])\n",
    "        y_val=convert_data(val_data[:,-1])\n",
    "        score_matrix[count], t_acc, t_f1, v_acc, v_f1=hyperparameters_opt_adam_ANN(X_train, y_train, X_val, y_val,param_range_learning_rate,param_range_weight_decay,num_epochs)\n",
    "        train_acc.append(t_acc)\n",
    "        train_f1.append(t_f1)\n",
    "        val_acc.append(v_acc)\n",
    "        val_f1.append(v_f1)\n",
    "        count+=1\n",
    "\n",
    "        for i,learning_rate in enumerate(param_range_learning_rate):\n",
    "            for j,momentum in enumerate(param_range_weight_decay):\n",
    "                final[i,j]=np.mean(score_matrix[:,i,j]) \n",
    "\n",
    "    print_acc_val(train_acc,train_f1,val_acc,val_f1)\n",
    "    index=np.unravel_index(final.argmax(), final.shape)\n",
    "    optimal_lr=param_range_learning_rate[index[0]]\n",
    "    optimal_weight_decay=param_range_weight_decay[index[1]]\n",
    "\n",
    "    print(\"Optimal value of Learning Rate is\",optimal_lr)\n",
    "    print(\"Optimal value of Weight Decay is\",optimal_weight_decay)    \n",
    "    \n",
    "    #Using optimal values to build ANN model                 \n",
    "    optimal_model, optimizer=classification_model(optimal_lr,optimal_weight_decay)\n",
    "    loss_list=[]\n",
    "    training_dataset=convert_data(dataset[:,0:-1])\n",
    "    for epoch in range(num_epochs):\n",
    "        y_pred = optimal_model(X_train)\n",
    "        y_pred = torch.squeeze(y_pred)\n",
    "        train_loss = weighted_binary_cross_entropy(y_pred, y_train)   \n",
    "        loss_list.append(train_loss.detach().numpy())\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    y_pred=y_pred.detach().numpy()\n",
    "    y_pred = np.where(y_pred>0.5, 1, 0) \n",
    "    final_train_accuracy, final_train_f1 = performance_measure(y_pred, y_train)\n",
    "    print(\"Final Train Accuracy is\", final_train_accuracy)\n",
    "    print(\"Final Train F1 score is\", final_train_f1)\n",
    "\n",
    "    return optimal_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xxw0xEdzXNjV",
   "metadata": {
    "id": "Xxw0xEdzXNjV"
   },
   "outputs": [],
   "source": [
    "def ann_model_test(model,test):\n",
    "    '''\n",
    "    Function to test the ANN model on test data\n",
    "    \n",
    "    Parameters:\n",
    "    model: model created using the optimal learning rate and weight decay values\n",
    "    test: test data\n",
    "\n",
    "    Return:\n",
    "    Prints the test set Accuracy, F1 score and the Confusion Matrix\n",
    "    '''\n",
    "    with torch.no_grad():# ensuring gradients are not being calculated for the test set data\n",
    "        y_true=test[:,-1]#last column containing the class labels\n",
    "        test=convert_data(test[:,0:-1])\n",
    "        y_pred=model(test)\n",
    "        y_pred=y_pred.detach().numpy()\n",
    "        y_pred_np= np.where(y_pred>0.5, 1, 0)\n",
    "        test_accuracy=accuracy_score(y_true,y_pred_np)\n",
    "        conf_matrix=confusion_matrix(y_true,y_pred_np)\n",
    "        test_f1=f1_score(y_true,y_pred_np)\n",
    "        \n",
    "        print(\"Test Accuracy is\", round_off_values(test_accuracy)) \n",
    "        print(\"Test F1 Score is\", round_off_values(test_f1))\n",
    "        plot_confusion_matrix(y_true, y_pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a97fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_adam_model=ann_model_adam_train(train_mov_np,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a409768",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NqbHxWxa0yjh",
    "outputId": "ddb51ae0-0670-458e-dfda-30574eb2b1f0"
   },
   "source": [
    "ann_model_test(ann_adam_model,test_mov_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ebce06",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3061a6d",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/loss-function-with-small-amount-of-positives/70900"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_Final_May_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
